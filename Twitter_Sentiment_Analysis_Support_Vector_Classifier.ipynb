{"metadata":{"colab":{"name":"Twitter Sentiment Analysis - Support Vector Classifier.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Basic Libraries","metadata":{"id":"iwdbTJ_ZIw7y","colab_type":"text"}},{"cell_type":"code","source":"import sklearn\nimport numpy as np\nimport pandas as pd","metadata":{"id":"QwA9OqE1IY53","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2023-06-22T09:47:35.452166Z","iopub.execute_input":"2023-06-22T09:47:35.452588Z","iopub.status.idle":"2023-06-22T09:47:35.457444Z","shell.execute_reply.started":"2023-06-22T09:47:35.452557Z","shell.execute_reply":"2023-06-22T09:47:35.456247Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Import Data","metadata":{"id":"f1O1Bg_pI1VD","colab_type":"text"}},{"cell_type":"code","source":"# training data\ntrain = pd.read_csv(\"/train.csv\")\n\n# test data\ntest = pd.read_csv(\"/test.csv\")","metadata":{"id":"Galut_WrI4bV","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2023-06-22T09:47:35.459290Z","iopub.execute_input":"2023-06-22T09:47:35.459637Z","iopub.status.idle":"2023-06-22T09:47:35.569101Z","shell.execute_reply.started":"2023-06-22T09:47:35.459601Z","shell.execute_reply":"2023-06-22T09:47:35.567950Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration (Exploratory Data Analysis)","metadata":{"id":"rvtCODUEJciM","colab_type":"text"}},{"cell_type":"code","source":"train.head()","metadata":{"id":"Mni8YItfJcSs","colab_type":"code","outputId":"c880fcf3-9269-450b-ad39-c3a4af89bf88","colab":{"base_uri":"https://localhost:8080/","height":204},"execution":{"iopub.status.busy":"2023-06-22T09:47:35.570238Z","iopub.execute_input":"2023-06-22T09:47:35.570646Z","iopub.status.idle":"2023-06-22T09:47:35.603511Z","shell.execute_reply.started":"2023-06-22T09:47:35.570611Z","shell.execute_reply":"2023-06-22T09:47:35.602707Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   id  label                                              tweet\n0   1      0   @user when a father is dysfunctional and is s...\n1   2      0  @user @user thanks for #lyft credit i can't us...\n2   3      0                                bihday your majesty\n3   4      0  #model   i love u take with u all the time in ...\n4   5      0             factsguide: society now    #motivation","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.tail()","metadata":{"id":"lRex8owXJV40","colab_type":"code","outputId":"a878a1d5-58e2-4578-cb46-167ee6a2e74f","colab":{"base_uri":"https://localhost:8080/","height":204},"execution":{"iopub.status.busy":"2023-06-22T09:47:35.605594Z","iopub.execute_input":"2023-06-22T09:47:35.606484Z","iopub.status.idle":"2023-06-22T09:47:35.617122Z","shell.execute_reply.started":"2023-06-22T09:47:35.606450Z","shell.execute_reply":"2023-06-22T09:47:35.615825Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"          id                                              tweet\n17192  49155  thought factory: left-right polarisation! #tru...\n17193  49156  feeling like a mermaid ð #hairflip #neverre...\n17194  49157  #hillary #campaigned today in #ohio((omg)) &am...\n17195  49158  happy, at work conference: right mindset leads...\n17196  49159  my   song \"so glad\" free download!  #shoegaze ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17192</th>\n      <td>49155</td>\n      <td>thought factory: left-right polarisation! #tru...</td>\n    </tr>\n    <tr>\n      <th>17193</th>\n      <td>49156</td>\n      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n    </tr>\n    <tr>\n      <th>17194</th>\n      <td>49157</td>\n      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n    </tr>\n    <tr>\n      <th>17195</th>\n      <td>49158</td>\n      <td>happy, at work conference: right mindset leads...</td>\n    </tr>\n    <tr>\n      <th>17196</th>\n      <td>49159</td>\n      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# non-racist/sexist related tweets\nsum(train[\"label\"] == 0)","metadata":{"id":"jAUIxDOYJmvt","colab_type":"code","outputId":"a385b811-8a70-4eeb-f33f-037a723040a4","colab":{"base_uri":"https://localhost:8080/","height":34},"execution":{"iopub.status.busy":"2023-06-22T09:47:35.618674Z","iopub.execute_input":"2023-06-22T09:47:35.619176Z","iopub.status.idle":"2023-06-22T09:47:35.634866Z","shell.execute_reply.started":"2023-06-22T09:47:35.619138Z","shell.execute_reply":"2023-06-22T09:47:35.633690Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"29720"},"metadata":{}}]},{"cell_type":"code","source":"# racist/sexist related tweets\nsum(train[\"label\"] == 1)","metadata":{"id":"ijAyVcYjKPc_","colab_type":"code","outputId":"6def6736-d9f5-4853-faa0-26451a3af937","colab":{"base_uri":"https://localhost:8080/","height":34},"execution":{"iopub.status.busy":"2023-06-22T09:47:35.636481Z","iopub.execute_input":"2023-06-22T09:47:35.636909Z","iopub.status.idle":"2023-06-22T09:47:35.650644Z","shell.execute_reply.started":"2023-06-22T09:47:35.636871Z","shell.execute_reply":"2023-06-22T09:47:35.649037Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"2242"},"metadata":{}}]},{"cell_type":"code","source":"# check if there are any missing values\ntrain.isnull().sum()\n#train.isnull().values.any()","metadata":{"id":"mubp2OU0M2-M","colab_type":"code","outputId":"e2b3fe4e-abc5-4ebb-9354-6e6d520c2f12","colab":{"base_uri":"https://localhost:8080/","height":85},"execution":{"iopub.status.busy":"2023-06-22T09:47:35.652197Z","iopub.execute_input":"2023-06-22T09:47:35.652576Z","iopub.status.idle":"2023-06-22T09:47:35.675845Z","shell.execute_reply.started":"2023-06-22T09:47:35.652535Z","shell.execute_reply":"2023-06-22T09:47:35.674706Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"id       0\nlabel    0\ntweet    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data cleaning","metadata":{"id":"m9uidliWUL9t","colab_type":"text"}},{"cell_type":"code","source":"#install tweet-preprocessor to clean tweets\n!pip install tweet-preprocessor","metadata":{"id":"G9BW8zWhKWbn","colab_type":"code","outputId":"238f5172-e76a-4959-d511-90f7fb247a61","colab":{"base_uri":"https://localhost:8080/","height":34},"execution":{"iopub.status.busy":"2023-06-22T09:47:35.677905Z","iopub.execute_input":"2023-06-22T09:47:35.678368Z","iopub.status.idle":"2023-06-22T09:47:48.237596Z","shell.execute_reply.started":"2023-06-22T09:47:35.678328Z","shell.execute_reply":"2023-06-22T09:47:48.236393Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Collecting tweet-preprocessor\n  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\nInstalling collected packages: tweet-preprocessor\nSuccessfully installed tweet-preprocessor-0.6.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# remove special characters using the regular expression library\nimport re\n\n#set up punctuations we want to be replaced\nREPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\nREPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")","metadata":{"id":"iB47T9w3YNry","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2023-06-22T09:47:48.244390Z","iopub.execute_input":"2023-06-22T09:47:48.244791Z","iopub.status.idle":"2023-06-22T09:47:48.252804Z","shell.execute_reply.started":"2023-06-22T09:47:48.244754Z","shell.execute_reply":"2023-06-22T09:47:48.251151Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import preprocessor as p\n\n# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\ndef clean_tweets(df):\n  tempArr = []\n  for line in df:\n    # send to tweet_processor\n    tmpL = p.clean(line)\n    # remove puctuation\n    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n    tempArr.append(tmpL)\n  return tempArr","metadata":{"id":"6Kaf60xXPryT","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2023-06-22T09:47:48.254268Z","iopub.execute_input":"2023-06-22T09:47:48.254644Z","iopub.status.idle":"2023-06-22T09:47:48.283057Z","shell.execute_reply.started":"2023-06-22T09:47:48.254614Z","shell.execute_reply":"2023-06-22T09:47:48.281560Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# clean training data\ntrain_tweet = clean_tweets(train[\"tweet\"])\ntrain_tweet = pd.DataFrame(train_tweet)","metadata":{"id":"B5BFI2HEUm6W","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2023-06-22T09:47:48.285011Z","iopub.execute_input":"2023-06-22T09:47:48.285466Z","iopub.status.idle":"2023-06-22T09:47:53.443801Z","shell.execute_reply.started":"2023-06-22T09:47:48.285427Z","shell.execute_reply":"2023-06-22T09:47:53.442840Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# append cleaned tweets to the training data\ntrain[\"clean_tweet\"] = train_tweet\n\n# compare the cleaned and uncleaned tweets\ntrain.head(10)","metadata":{"id":"suq-CJYUXAT8","colab_type":"code","outputId":"6379536e-345b-4887-9773-dd50708fc52c","colab":{"base_uri":"https://localhost:8080/","height":359},"execution":{"iopub.status.busy":"2023-06-22T09:47:53.445320Z","iopub.execute_input":"2023-06-22T09:47:53.445720Z","iopub.status.idle":"2023-06-22T09:47:53.462302Z","shell.execute_reply.started":"2023-06-22T09:47:53.445683Z","shell.execute_reply":"2023-06-22T09:47:53.461270Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   id  label                                              tweet  \\\n0   1      0   @user when a father is dysfunctional and is s...   \n1   2      0  @user @user thanks for #lyft credit i can't us...   \n2   3      0                                bihday your majesty   \n3   4      0  #model   i love u take with u all the time in ...   \n4   5      0             factsguide: society now    #motivation   \n5   6      0  [2/2] huge fan fare and big talking before the...   \n6   7      0   @user camping tomorrow @user @user @user @use...   \n7   8      0  the next school year is the year for exams.ð...   \n8   9      0  we won!!! love the land!!! #allin #cavs #champ...   \n9  10      0   @user @user welcome here !  i'm   it's so #gr...   \n\n                                         clean_tweet  \n0  when a father is dysfunctional and is so selfi...  \n1  thanks for credit i cant use cause they dont o...  \n2                                bihday your majesty  \n3            i love u take with u all the time in ur  \n4                             factsguide society now  \n5  2 2 huge fan fare and big talking before they ...  \n6                             camping tomorrow danny  \n7  the next school year is the year for exams can...  \n8                               we won love the land  \n9                           welcome here  im its so   ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>tweet</th>\n      <th>clean_tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>@user when a father is dysfunctional and is s...</td>\n      <td>when a father is dysfunctional and is so selfi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>@user @user thanks for #lyft credit i can't us...</td>\n      <td>thanks for credit i cant use cause they dont o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>bihday your majesty</td>\n      <td>bihday your majesty</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>#model   i love u take with u all the time in ...</td>\n      <td>i love u take with u all the time in ur</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>factsguide: society now    #motivation</td>\n      <td>factsguide society now</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0</td>\n      <td>[2/2] huge fan fare and big talking before the...</td>\n      <td>2 2 huge fan fare and big talking before they ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n      <td>@user camping tomorrow @user @user @user @use...</td>\n      <td>camping tomorrow danny</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0</td>\n      <td>the next school year is the year for exams.ð...</td>\n      <td>the next school year is the year for exams can...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0</td>\n      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n      <td>we won love the land</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>0</td>\n      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n      <td>welcome here  im its so</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# clean the test data and append the cleaned tweets to the test data\ntest_tweet = clean_tweets(test[\"tweet\"])\ntest_tweet = pd.DataFrame(test_tweet)\n# append cleaned tweets to the training data\ntest[\"clean_tweet\"] = test_tweet\n\n# compare the cleaned and uncleaned tweets\ntest.tail()","metadata":{"id":"0_dHhhn2bHYL","colab_type":"code","outputId":"a0690808-0cd6-4bc0-fde6-8c362af280a4","colab":{"base_uri":"https://localhost:8080/","height":204},"execution":{"iopub.status.busy":"2023-06-22T09:47:53.463443Z","iopub.execute_input":"2023-06-22T09:47:53.463850Z","iopub.status.idle":"2023-06-22T09:47:56.145073Z","shell.execute_reply.started":"2023-06-22T09:47:53.463812Z","shell.execute_reply":"2023-06-22T09:47:56.144257Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"          id                                              tweet  \\\n17192  49155  thought factory: left-right polarisation! #tru...   \n17193  49156  feeling like a mermaid ð #hairflip #neverre...   \n17194  49157  #hillary #campaigned today in #ohio((omg)) &am...   \n17195  49158  happy, at work conference: right mindset leads...   \n17196  49159  my   song \"so glad\" free download!  #shoegaze ...   \n\n                                             clean_tweet  \n17192       thought factory left right polarisation &gt3  \n17193                             feeling like a mermaid  \n17194  today in omg &amp used words like assets&ampli...  \n17195  happy at work conference right mindset leads t...  \n17196                      my song so glad free download  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>clean_tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>17192</th>\n      <td>49155</td>\n      <td>thought factory: left-right polarisation! #tru...</td>\n      <td>thought factory left right polarisation &amp;gt3</td>\n    </tr>\n    <tr>\n      <th>17193</th>\n      <td>49156</td>\n      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n      <td>feeling like a mermaid</td>\n    </tr>\n    <tr>\n      <th>17194</th>\n      <td>49157</td>\n      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n      <td>today in omg &amp;amp used words like assets&amp;ampli...</td>\n    </tr>\n    <tr>\n      <th>17195</th>\n      <td>49158</td>\n      <td>happy, at work conference: right mindset leads...</td>\n      <td>happy at work conference right mindset leads t...</td>\n    </tr>\n    <tr>\n      <th>17196</th>\n      <td>49159</td>\n      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n      <td>my song so glad free download</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Test and Train split\n","metadata":{"id":"QNJ7n2jXbzwl","colab_type":"text"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# extract the labels from the train data\ny = train.label.values\n\n# use 70% for the training and 30% for the test\nx_train, x_test, y_train, y_test = train_test_split(train.clean_tweet.values, y, \n                                                    stratify=y, \n                                                    random_state=1, \n                                                    test_size=0.3, shuffle=True)","metadata":{"id":"LQJjcE_Tb4JU","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2023-06-22T09:47:56.146025Z","iopub.execute_input":"2023-06-22T09:47:56.146490Z","iopub.status.idle":"2023-06-22T09:47:56.309834Z","shell.execute_reply.started":"2023-06-22T09:47:56.146465Z","shell.execute_reply":"2023-06-22T09:47:56.308464Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Vectorize tweets using CountVectorizer","metadata":{"id":"EP0vIgrcdMSM","colab_type":"text"}},{"cell_type":"markdown","source":"CountVectorizer Example","metadata":{"id":"O6M8mUI9n9fR","colab_type":"text"}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","metadata":{"id":"k-5RsyYJBGPB","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2023-06-22T09:47:56.311139Z","iopub.execute_input":"2023-06-22T09:47:56.311454Z","iopub.status.idle":"2023-06-22T09:47:56.330258Z","shell.execute_reply.started":"2023-06-22T09:47:56.311428Z","shell.execute_reply":"2023-06-22T09:47:56.329335Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"documents = [\"This is Import Data's Youtube channel\",\n             \"Data science is my passion and it is fun!\",\n             \"Please subscribe to my channel\"]\n\n# initializing the countvectorizer\nvectorizer = CountVectorizer()\n\n# tokenize and make the document into a matrix\ndocument_term_matrix = vectorizer.fit_transform(documents)\n\n# check the result\npd.DataFrame(document_term_matrix.toarray(), columns = vectorizer.get_feature_names_out())","metadata":{"id":"VSsrvD_nA0pQ","colab_type":"code","outputId":"9a8267de-53b3-4415-ee0a-589184c2ca59","colab":{"base_uri":"https://localhost:8080/","height":142},"execution":{"iopub.status.busy":"2023-06-22T09:53:18.249151Z","iopub.execute_input":"2023-06-22T09:53:18.250171Z","iopub.status.idle":"2023-06-22T09:53:18.267138Z","shell.execute_reply.started":"2023-06-22T09:53:18.250135Z","shell.execute_reply":"2023-06-22T09:53:18.265730Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"   and  channel  data  fun  import  is  it  my  passion  please  science  \\\n0    0        1     1    0       1   1   0   0        0       0        0   \n1    1        0     1    1       0   2   1   1        1       0        1   \n2    0        1     0    0       0   0   0   1        0       1        0   \n\n   subscribe  this  to  youtube  \n0          0     1   0        1  \n1          0     0   0        0  \n2          1     0   1        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>and</th>\n      <th>channel</th>\n      <th>data</th>\n      <th>fun</th>\n      <th>import</th>\n      <th>is</th>\n      <th>it</th>\n      <th>my</th>\n      <th>passion</th>\n      <th>please</th>\n      <th>science</th>\n      <th>subscribe</th>\n      <th>this</th>\n      <th>to</th>\n      <th>youtube</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n# vectorize tweets for model building\nvectorizer = CountVectorizer(binary=True, stop_words='english')\n\n# learn a vocabulary dictionary of all tokens in the raw documents\nvectorizer.fit(list(x_train) + list(x_test))\n\n# transform documents to document-term matrix\nx_train_vec = vectorizer.transform(x_train)\nx_test_vec = vectorizer.transform(x_test)","metadata":{"id":"reQP8v7Gb36g","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2023-06-22T09:53:21.416308Z","iopub.execute_input":"2023-06-22T09:53:21.416710Z","iopub.status.idle":"2023-06-22T09:53:22.172562Z","shell.execute_reply.started":"2023-06-22T09:53:21.416676Z","shell.execute_reply":"2023-06-22T09:53:22.171443Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Model building","metadata":{"id":"nv02BKQ-ee_m","colab_type":"text"}},{"cell_type":"markdown","source":"Apply Support Vetor Classifier (SVC)","metadata":{"id":"it_BrO5qehpR","colab_type":"text"}},{"cell_type":"code","source":"from sklearn import svm\n# classify using support vector classifier\nsvm = svm.SVC(kernel = 'linear', probability=True)\n\n# fit the SVC model based on the given training data\nprob = svm.fit(x_train_vec, y_train).predict_proba(x_test_vec)\n\n# perform classification and prediction on samples in x_test\ny_pred_svm = svm.predict(x_test_vec)","metadata":{"id":"VEXBqGBGeeG6","colab_type":"code","colab":{},"execution":{"iopub.status.busy":"2023-06-22T09:53:27.576310Z","iopub.execute_input":"2023-06-22T09:53:27.576754Z","iopub.status.idle":"2023-06-22T09:54:42.488330Z","shell.execute_reply.started":"2023-06-22T09:53:27.576722Z","shell.execute_reply":"2023-06-22T09:54:42.487294Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy score for SVC\n","metadata":{"id":"8SJ5l9iehjBT","colab_type":"text"}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(\"Accuracy score for SVC is: \", accuracy_score(y_test, y_pred_svm) * 100, '%')","metadata":{"id":"lERS4fXwea7B","colab_type":"code","outputId":"a1865915-6431-4097-d950-d7c6310fa74e","colab":{"base_uri":"https://localhost:8080/","height":34},"execution":{"iopub.status.busy":"2023-06-22T09:54:42.489921Z","iopub.execute_input":"2023-06-22T09:54:42.490246Z","iopub.status.idle":"2023-06-22T09:54:42.497281Z","shell.execute_reply.started":"2023-06-22T09:54:42.490219Z","shell.execute_reply":"2023-06-22T09:54:42.496337Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Accuracy score for SVC is:  94.86912086766085 %\n","output_type":"stream"}]}]}